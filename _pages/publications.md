---
title: "Publications"
permalink: /publications/
layout: single
comments: false
---

## Accepted Papers

<span style="font-size:60%">**[11] FaithUn: Toward Faithful Forgetting in Language Models by Investigating the Interconnectedness of Knowledge** [[pdf]](https://arxiv.org/abs/2502.19207) <span class="red">[[Joint work with Adobe Research]](https://research.adobe.com/publication/faithun-toward-faithful-forgetting-in-language-models-by-investigating-the-interconnectedness-of-knowledge/)</span></span>  
<span style="font-size:60%"><u>Nakyeong Yang</u>, Minsung Kim, Seunghyun Yoon, Joongbo Shin, Kyomin Jung  
[EMNLP 2025](https://2025.emnlp.org)</span>

<span style="font-size:60%">**[10] Avoidance Decoding for Diverse Multi-Branch Story Generation**</span>  
<span style="font-size:60%">Kyeongman Park, <u>Nakyeong Yang</u>, Kyomin Jung  
[EMNLP 2025](https://2025.emnlp.org)</span>

<span style="font-size:60%">**[9] Unplug and Play Language Models: Decomposing Experts in Language Models at Inference Time** [[pdf]](https://arxiv.org/abs/2404.11916)</span>  
<span style="font-size:60%"><u>Nakyeong Yang</u>, Jiwon Moon, Junseok Kim, Yunah Jang, Kyomin Jung  
[CIKM 2025](https://cikm2025.org)</span>

<span style="font-size:60%">**[8] MVMR: A New Framework for Evaluating Faithfulness of Video Moment Retrieval against Multiple Distractors** [[pdf]](https://dl.acm.org/doi/10.1145/3627673.3679838) <span style="color:red;">[[Joint work with Adobe Research]](https://research.adobe.com/publication/mvmr-a-new-framework-for-evaluating-faithfulness-of-video-moment-retrieval-against-multiple-distractors/)</span></span>  
<span style="font-size:60%"><u>Nakyeong Yang</u>, Minsung Kim, Seunghyun Yoon, Joongbo Shin, Kyomin Jung  
[CIKM 2024 (Oral)](https://cikm2024.org/)</span>

<span style="font-size:60%">**[7] Mitigating Biases for Instruction-following Language Models via Bias Neurons Elimination** [[pdf]](https://aclanthology.org/2024.acl-long.490/)</span>  
<span style="font-size:60%"><u>Nakyeong Yang</u>, Taegwan Kang, Jungkyu Choi, Honglak Lee, Kyomin Jung  
[ACL 2024](https://2024.aclweb.org/)

<span style="font-size:60%">**[6] LongStory: Coherent, Complete and Length Controlled Long story Generation** [[pdf]](https://arxiv.org/abs/2311.15208)</span>  
<span style="font-size:60%">Kyeongman Park, <u>Nakyeong Yang</u>, Kyomin Jung  
[PAKDD 2024 (Oral)](https://pakdd2024.org/)

<span style="font-size:60%">**[5] Task-specific Compression for Multi-task Language Models using Attribution-based Pruning** [[pdf]](https://aclanthology.org/2023.findings-eacl.43/)</span>  
<span style="font-size:60%"><u>Nakyeong Yang</u>, Yunah Jang, Hwanhee Lee, Seohyeong Jeong, Kyomin Jung  
[Findings of the Association for Computational Linguistics: EACL 2023](https://2023.eacl.org/)

<span style="font-size:60%">**[4] Multi-View Zero-Shot Open Intent Induction from Dialogues: Multi Domain Batch and Proxy Gradient Transfer** [[pdf]](https://arxiv.org/abs/2303.13099)</span>  
<span style="font-size:60%">Hyukhun Koh, Haesung Pyun, <u>Nakyeong Yang</u>, Kyomin Jung  
[SIGDial 2023 Workshop (DSTC 11)](https://dstc11.dstc.community/)

<span style="font-size:60%">**[3] Deriving Explainable Discriminative Attributes Using Confusion About Counterfactual Class** [[pdf]](https://ieeexplore.ieee.org/document/9747693)</span>  
<span style="font-size:60%"><u>Nakyeong Yang</u>, Taegwan Kang, Kyomin Jung  
[ICASSP 2022 (Oral)](https://2022.ieeeicassp.org/)

<span style="font-size:60%">**[2] Semantic and Explainable Research-related Recommendation System based on Semi-supervised Methodology using BERT and LDA models** [[pdf]](https://www.sciencedirect.com/science/article/abs/pii/S0957417421015232)</span>  
<span style="font-size:60%"><u>Nakyeong Yang</u>, Jeongje Jo, Myeongjun Jeon, Wooju Kim, Juyoung Kang  
[Expert Systems with Applications (2022)](https://www.sciencedirect.com/journal/expert-systems-with-applications)

<span style="font-size:60%">**[1] RABERT: Relation-Aware BERT for Target-Oriented Opinion Words Extraction** [[pdf]](https://dl.acm.org/doi/abs/10.1145/3459637.3482165)</span>  
<span style="font-size:60%">Taegwan Kang, Minwoo Lee, <u>Nakyeong Yang</u>, Kyomin Jung  
[CIKM 2021](https://www.cikm2021.org/)



## ArXiv

<span style="font-size:60%">**[3] Persona Switch: Mixing Distinct Perspectives in Decoding Time** [pdf]</span>  
<span style="font-size:60%">Junseok Kim, <u>Nakyeong Yang</u>, Kyomin Jung

<span style="font-size:60%">**[2] Rethinking Post-Unlearning Behavior of Large Vision-Language Models** [[pdf]](https://arxiv.org/abs/2506.02541)</span>  
<span style="font-size:60%">Minsung Kim, <u>Nakyeong Yang</u>, Kyomin Jung  

<span style="font-size:60%">**[1] Persona is a Double-edged Sword: Mitigating the Negative Impact of Role-playing Prompts in Zero-shot Reasoning Tasks** [[pdf]](https://arxiv.org/abs/2408.08631)</span>  
<span style="font-size:60%">Junseok Kim, <u>Nakyeong Yang</u>, Kyomin Jung  
